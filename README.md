# Distributed Outbox Event Streaming Architecture

This project implements an **event-driven outbox pattern** using Kafka, Debezium, Kafka Streams, and Schema Registry to propagate state changes from a PostgreSQL-based microservice into a shared, normalized event stream that can be consumed by downstream services (e.g., shipment service, S3 sinks, etc.).



## ğŸ— Architecture Overview
```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  PostgreSQL (DB)   â”‚
          â”‚  â”€â”€ Outbox Table   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Debezium         â”‚
        â”‚ Postgres Connector   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      Kafka Topic: orders.private.outbox
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Kafka Streams  â”‚
         â”‚      App       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      Kafka Topic: orders.public.outbox.v1
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚       â”‚        â”‚
         â–¼       â–¼        â–¼
  Shipment  S3 Sink   Other Services
   Service   (via     (Optional fan-out)
  (Consumer) Connector)
```

- **Debezium** monitors changes in the outbox table (`outboxevent`) via logical decoding.
- **Kafka Streams** normalizes and transforms the private JSON-based stream to a public Avro-based stream.
- **Schema Registry** ensures schema evolution and validation.
- **Consumers** (e.g., shipment-service) deserialize strongly typed Avro messages.



## ğŸ”§ Modules

| Module              | Description |
|---------------------|-------------|
| `order-service`     | Produces domain events into the `outboxevent` table (CDC source). |
| `debezium`          | PostgreSQL connector with logical decoding. |
| `kafka-streams`     | Reads from private JSON topic, normalizes into typed Avro records. |
| `shipment-service`  | Sample consumer of the public outbox stream using Specific Avro. |



## ğŸ§  Key Concepts

### ğŸ” Outbox Pattern
- Ensures reliable propagation of domain events by writing to an outbox table as part of the local transaction.
- Eliminates dual-write problems between DB and Kafka.

### ğŸ§¬ Schema Evolution with Avro
- Versioned topics (`orders.public.outbox.v1`) separate schema contracts.
- Avro ensures serialization compatibility with enforced schema types.

### ğŸ” Change Data Capture (CDC)
- Debezium reads logical changes using PostgreSQL's logical replication.
- Handles special PostgreSQL cases like TOAST columns:
    - See [Handling Unchanged TOAST Values](https://debezium.io/blog/2019/10/08/handling-unchanged-postgres-toast-values/)

### ğŸ“¦ Event Routing and Transformation
- Debezium connector transforms the CDC stream:
    - `ExtractNewRecordState` to unwrap payloads
    - `ByLogicalTableRouter` to rename topics
- Kafka Streams performs final enrichment and emits versioned Avro events.



## ğŸš¦ Key Behaviors

- **Null or `__debezium_unavailable_value` fields** are filtered to prevent deserialization failures.
- **Consumers** can independently subscribe to public topics without breaking changes via Avro + topic versioning.
- **Tombstones** can be handled if `tombstones.on.delete=true`, though dropped by default.



## ğŸ§ª Running Locally

```bash
make up
```

Then, interact via:

- `localhost:8080` â†’ Order service API
- `localhost:8091` â†’ Shipment service consumer logs

## ğŸ› ï¸ Generating Avro POJOs

To generate Java POJOs from your Avro schema files, run:

```bash
mvn generate-sources
```


## ğŸ“š References

- [The Schema Registry API is *Not* How You Use Schema with Kafka](https://medium.com/google-cloud/the-schema-registry-api-is-not-how-you-use-schema-with-kafka-3adb92f09764)
- [Is Kafka a Database (with ksqlDB)?](https://www.confluent.io/blog/is-kafka-a-database-with-ksqldb/)
- [Database Inside Out â€“ Martin Kleppmann](https://martin.kleppmann.com/2015/11/05/database-inside-out-at-oredev.html)
- [Handling Unchanged Postgres TOAST Values](https://debezium.io/blog/2019/10/08/handling-unchanged-postgres-toast-values/)
- [Debezium PostgreSQL Connector Docs](https://debezium.io/documentation/reference/stable/connectors/postgresql.html)



## ğŸ“ Future Enhancements

- Add schema validation and metrics.
- Implement event reprocessing and dead-letter handling.
- Enable S3 archival via Kafka Connect + LocalStack.
- Integrate observability with Prometheus and Micrometer.
